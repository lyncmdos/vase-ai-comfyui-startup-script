#!/bin/bash

# This file will be sourced in init.sh
# Namespace functions with provisioning_

# https://raw.githubusercontent.com/ai-dock/comfyui/main/config/provisioning/default.sh

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source /venv/main/bin/activate
COMFYUI_DIR=${WORKSPACE}/ComfyUI

# Packages are installed after nodes so we can fix them...

APT_PACKAGES=(
    "wget2"
    #"package-2"
)

PIP_PACKAGES=(
    "gguf"
    
)

# --- ã€ä¿®æ”¹ç‚¹1ã€‘è¿™é‡Œå¡«å…¥äº†ä½ éœ€è¦çš„æ‰€æœ‰æ’ä»¶ ---
NODES=(
    "https://github.com/ltdrdata/ComfyUI-Manager"
    "https://github.com/ltdrdata/ComfyUI-Impact-Pack"
    "https://github.com/ssitu/ComfyUI_UltimateSDUpscale"
    "https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes"
    "https://github.com/ltdrdata/was-node-suite-comfyui"
    "https://github.com/felixszeto/ComfyUI-RequestNodes"
    "https://github.com/heshengtao/comfyui_LLM_party"
    "https://github.com/Aaalice233/ComfyUI-Danbooru-Gallery"
    "https://github.com/yolain/ComfyUI-Easy-Use"
    "https://github.com/city96/ComfyUI-GGUF"
    "https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite"
    "https://github.com/Fannovel16/ComfyUI-Frame-Interpolation"
    "https://github.com/SeanScripts/ComfyUI-Unload-Model"
    "https://github.com/Artificial-Sweetener/comfyui-WhiteRabbit"
    "https://github.com/rgthree/rgthree-comfy"
    "https://github.com/kijai/ComfyUI-KJNodes"
    "https://github.com/ClownsharkBatwing/RES4LYF"
    "https://github.com/chflame163/ComfyUI_LayerStyle"
    "https://github.com/PowerHouseMan/ComfyUI-AdvancedLivePortrait"
    "https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler"
    "https://github.com/kijai/ComfyUI-Florence2"
    "https://github.com/pollockjj/ComfyUI-MultiGPU"
    "https://github.com/Derfuu/Derfuu_ComfyUI_ModdedNodes"
    "https://github.com/giriss/comfy-image-saver"
    "https://github.com/Smirnov75/ComfyUI-mxToolkit"
    "https://github.com/EllangoK/ComfyUI-post-processing-nodes"
    "https://github.com/digitaljohn/comfyui-propost"
    "https://github.com/jamesWalker55/comfyui-various"
    "https://github.com/evanspearman/ComfyMath"
    "https://github.com/JPS-GER/ComfyUI_JPS-Nodes"
    "https://github.com/chrisfreilich/virtuoso-nodes"
    "https://github.com/plugcrypt/CRT-Nodes"
    "https://github.com/edelvarden/comfyui_image_metadata_extension"
    "https://github.com/adieyal/comfyui-dynamicprompts"
    "https://github.com/pythongosssss/ComfyUI-Custom-Scripts"
)

WORKFLOWS=(
    
)

# --- ã€ä¿®æ”¹ç‚¹2ã€‘Checkpoint å¤§æ¨¡å‹æ”¾è¿™é‡Œ ---
CHECKPOINT_MODELS=(
    # ç¤ºä¾‹ (Z-image-turbo æˆ–è€… Flux):
    # "https://civitai.com/api/download/models/798204?type=Model&format=SafeTensor&size=full&fp=fp16"
    # "https://civitai.com/api/download/models/2471283?type=Model&format=SafeTensor&size=pruned&fp=fp16"
    # "https://civitai.com/api/download/models/2388548?type=Model&format=SafeTensor&size=full&fp=fp8"
    #"https://civitai.com/api/download/models/2520801?type=Model&format=GGUF&size=full&fp=fp8"
    #"https://civitai.com/api/download/models/2520805?type=Model&format=GGUF&size=full&fp=fp8"
)

UNET_MODELS=(
    "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_bf16.safetensors"
    "https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors"
    #"https://civitai.com/api/download/models/2490517?type=Model&format=SafeTensor&size=pruned&fp=fp8"
)

LORA_MODELS=(
    "https://civitai.com/api/download/models/2471161?type=Model&format=SafeTensor"
)

VAE_MODELS=(
    "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors"
    #"https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors"
    "https://huggingface.co/Owen777/UltraFlux-v1/resolve/main/vae/diffusion_pytorch_model.safetensors"
)

# åŸç”Ÿæ”¯æŒçš„ ESRGAN ç›®å½•
ESRGAN_MODELS=(
)

# åŸç”Ÿæ”¯æŒçš„ ControlNet ç›®å½•
CONTROLNET_MODELS=(
)

# --- ã€ä¿®æ”¹ç‚¹3ã€‘æ–°å¢è‡ªå®šä¹‰æ–‡ä»¶å¤¹å¯¹åº”çš„æ¨¡å‹åˆ—è¡¨ ---
# å¡«å…¥ text_encoders æ¨¡å‹é“¾æ¥
TEXT_ENCODER_MODELS=(
    "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors"
    #"https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors"
    # "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors"
)

# å¡«å…¥ upscale_models æ¨¡å‹é“¾æ¥ (æœ‰äº›æ”¾åœ¨ esrgan é‡Œï¼Œæœ‰äº›æ”¾åœ¨è¿™)
UPSCALE_MODELS=(
    "https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth"
)

# å¡«å…¥ LLM æ¨¡å‹é“¾æ¥
LLM_MODELS=(
    "https://huggingface.co/Qwen/Qwen3-8B-GGUF/resolve/main/Qwen3-8B-Q8_0.gguf"
    #"https://huggingface.co/DavidAU/Qwen3-8B-Hivemind-Instruct-Heretic-Abliterated-Uncensored-NEO-Imatrix-GGUF/resolve/main/Qwen3-8B-Hivemind-Inst-Hrtic-Ablit-Uncensored-Q8_0.gguf"
    #"https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q8_0.gguf?download=true"
    "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct-GGUF/resolve/main/Qwen3VL-8B-Instruct-Q8_0.gguf"
)

### DO NOT EDIT BELOW HERE UNLESS YOU KNOW WHAT YOU ARE DOING ###

function provisioning_start() {
    # 1. å®‰è£…åŸºç¡€å·¥å…·
    echo "Installing wget2 and uv for maximum speed..."
    sudo apt-get update > /dev/null 2>&1
    sudo apt-get install -y wget2 > /dev/null 2>&1
    
    # 2. å®‰è£… uv
    curl -LsSf https://astral.sh/uv/install.sh | sh
    source $HOME/.cargo/env
    source $HOME/.local/bin/env

    # 3. ã€å…³é”®æ–°å¢ã€‘ç«‹åˆ»å®‰è£… huggingface_hub ä»¥å¯ç”¨ CLI
    # ä½¿ç”¨ --system å®‰è£…åˆ°ç³»ç»Ÿç¯å¢ƒï¼Œç¡®ä¿å…¨å±€å¯ç”¨
    printf "ğŸš€ Installing Hugging Face CLI...\n"
    uv pip install --system huggingface_hub[cli]
    
    provisioning_print_header

    # [çº¿ç¨‹1] å¤„ç†æ’ä»¶
    (
        provisioning_setup_nodes_and_pip
    ) &
    local pid_nodes_pip=$!

    # [çº¿ç¨‹2] å¤„ç†æ¨¡å‹
    (
        provisioning_download_all_models
    ) &
    local pid_models=$!

    wait $pid_nodes_pip
    wait $pid_models
    
    provisioning_print_end
}

# è¾…åŠ©å‡½æ•°: é›†ä¸­å¤„ç†æ‰€æœ‰æ¨¡å‹ä¸‹è½½ä»»åŠ¡
function provisioning_download_all_models() {
    echo "ğŸš€ å¯åŠ¨å…¨ç›®å½•å¹¶è¡Œä¸‹è½½æ¨¡å¼..."

    # æ¯ä¸ªç›®å½•éƒ½åŠ ä¸Š &ï¼Œè®©å®ƒä»¬åœ¨åå°å¹¶è¡Œè·‘
    provisioning_get_files "${COMFYUI_DIR}/models/checkpoints" "${CHECKPOINT_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/unet" "${UNET_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/loras" "${LORA_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/controlnet" "${CONTROLNET_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/vae" "${VAE_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/esrgan" "${ESRGAN_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/text_encoders" "${TEXT_ENCODER_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/upscale_models" "${UPSCALE_MODELS[@]}" &
    provisioning_get_files "${COMFYUI_DIR}/models/LLM" "${LLM_MODELS[@]}" &

    # å…³é”®ï¼šç­‰å¾…æ‰€æœ‰åå°ç›®å½•ä¸‹è½½ä»»åŠ¡å®Œæˆ
    wait
    echo "âœ¨ æ‰€æœ‰æ¨¡å‹ç›®å½•åŒæ­¥å®Œæˆï¼"
}

function provisioning_get_apt_packages() {
    if [[ -n $APT_PACKAGES ]]; then
            sudo $APT_INSTALL ${APT_PACKAGES[@]}
    fi
}
 
function provisioning_setup_nodes_and_pip() {
    local req_files=()
    local node_paths=()
    #export CMAKE_ARGS="-DLLAMA_CUDA=on"
    #export FORCE_CMAKE=1
    printf "å¼€å§‹å¹¶è¡Œå¤„ç†æ’ä»¶å…‹éš†...\n"

    # 1. å¹¶è¡Œå…‹éš†/æ›´æ–°æ’ä»¶
    for repo in "${NODES[@]}"; do
        dir="${repo##*/}"
        path="${COMFYUI_DIR}/custom_nodes/${dir}"
        node_paths+=("$path")
        
        if [[ -d $path ]]; then
            if [[ ${AUTO_UPDATE,,} != "false" ]]; then
                ( cd "$path" && git pull ) & 
            fi
        else
            git clone "${repo}" "${path}" --recursive &
        fi
        
        # é™åˆ¶ Git å¹¶å‘æ•°
        if [[ $(jobs -r | wc -l) -ge 64 ]]; then wait -n; fi
    done
    wait

    printf "æ’ä»¶ä¸‹è½½å®Œæˆï¼Œæ­£åœ¨æ•´ç†ä¾èµ–åˆ—è¡¨...\n"

    # 2. æ”¶é›†æ‰€æœ‰ requirements.txt
    for path in "${node_paths[@]}"; do
        requirements="${path}/requirements.txt"
        if [[ -e $requirements ]]; then
            req_files+=("-r" "$requirements")
        fi
    done

    # 3. ä½¿ç”¨ uv å®‰è£…ï¼ˆå»æ‰ --prefer-binaryï¼Œæ”¹ç”¨æ›´å…¼å®¹çš„å†™æ³•ï¼‰
    if [[ ${#req_files[@]} -gt 0 || ${#PIP_PACKAGES[@]} -gt 0 ]]; then
        printf "ğŸš€ ä½¿ç”¨ UV æé€Ÿå®‰è£…æ‰€æœ‰ä¾èµ–...\n"
        
        # --system: å®‰è£…åˆ°å½“å‰ Python ç¯å¢ƒ
        # --no-build: (å¯é€‰) å¦‚æœä½ ç»å¯¹ä¸æƒ³ç­‰å¾…ç¼–è¯‘ï¼Œå¯ä»¥åŠ è¿™ä¸ªã€‚ä½†å»ºè®®ä¸åŠ ï¼Œä»¥é˜²æŸäº›èŠ‚ç‚¹å®‰è£…å¤±è´¥ã€‚
        # uv ä¼šè‡ªåŠ¨å¹¶è¡Œä¸‹è½½ä¸‹è½½æ‰€æœ‰åŒ…ï¼Œæ¯” pip å¿«å¾—å¤šã€‚
        uv pip install --system "${PIP_PACKAGES[@]}" "${req_files[@]}"
    fi
    printf "ğŸš€ æ­£åœ¨å®‰è£…é¢„ç¼–è¯‘çš„ CUDA ç‰ˆ llama-cpp-python (å…ç¼–è¯‘)...\n"
    
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ä½ çš„ç¯å¢ƒæ˜¯ CUDA 12.x (cu121/cu122/cu123 é€šç”¨)
    # å¦‚æœä½ çš„ç¯å¢ƒæ˜¯å¾ˆè€çš„ CUDA 11.8ï¼ŒæŠŠä¸‹é¢çš„ cu121 æ”¹æˆ cu118
    uv pip install --system llama-cpp-python \
        --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124
}

function provisioning_get_files() {
    if [[ -z $2 ]]; then return 1; fi
    local dir="$1"
    shift
    local arr=("$@")
    
    [[ ${#arr[@]} -eq 0 ]] && return 0

    mkdir -p "$dir"
    printf "ğŸ“‚ ç›®å½•å¹¶å‘å¼€å¯: %s (%s ä¸ªæ–‡ä»¶)\n" "$dir" "${#arr[@]}"
    
    # å†…éƒ¨ä»ç„¶ä¿æŒä¸€å®šçš„å¹¶å‘ï¼Œä½†å› ä¸ºå¤–éƒ¨å·²ç»å¹¶è¡Œäº†ï¼Œè¿™é‡Œå¯ä»¥è®¾å°ä¸€ç‚¹
    local max_internal_jobs=4
    local count=0

    for url in "${arr[@]}"; do
        [[ $url =~ ^# ]] && continue
        
        provisioning_download "${url}" "${dir}" &
        
        ((count++))
        if (( count >= max_internal_jobs )); then
            wait -n
            ((count--))
        fi
    done
    wait
}

function provisioning_print_header() {
    printf "\n##############################################\n#                                            #\n#          Provisioning container            #\n#                                            #\n#         This will take some time           #\n#                                            #\n# Your container will be ready on completion #\n#                                            #\n##############################################\n\n"
}

function provisioning_print_end() {
    printf "\nProvisioning complete:  Application will start now\n\n"
}

# Download from $1 URL to $2 file path
# Download from $1 URL to $2 file path
function provisioning_download() {
    local url="$1"
    local dir="$2"
    local auth_token=""

    # 1. æ¸…ç† URL ä¸­çš„å‚æ•° (ä¾‹å¦‚ ?download=true)ï¼Œé˜²æ­¢å¹²æ‰°è§£æ
    local clean_url="${url%%\?*}"

    [[ -n $HF_TOKEN && $url =~ huggingface\.co ]] && auth_token="$HF_TOKEN"
    [[ -n $CIVITAI_TOKEN && $url =~ civitai\.com ]] && auth_token="$CIVITAI_TOKEN"

    local filename=$(basename "$clean_url")

    # 2. åˆ¤æ–­æ˜¯å¦ä¸º HuggingFace é“¾æ¥
    if [[ $clean_url =~ huggingface\.co ]]; then
        # æ­£åˆ™è¡¨è¾¾å¼ï¼šæå– Repo å’Œ æ–‡ä»¶è·¯å¾„
        # åŒ¹é…æ ¼å¼: huggingface.co/ USER / REPO / (resolve|blob) / BRANCH / PATH...
        if [[ $clean_url =~ huggingface\.co/([^/]+/[^/]+)/(resolve|blob)/([^/]+)/(.+) ]]; then
            local repo_id="${BASH_REMATCH[1]}"
            local branch="${BASH_REMATCH[3]}" # é€šå¸¸æ˜¯ mainï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯å…¶ä»–åˆ†æ”¯
            local file_path="${BASH_REMATCH[4]}"
            
            printf "âš¡ [HF-CLI] Detecting: %s -> %s\n" "$repo_id" "$file_path"
            
            # ä½¿ç”¨ huggingface-cli ä¸‹è½½
            # --local-dir-use-symlinks False: ç¡®ä¿ä¸‹è½½çš„æ˜¯å®ä½“æ–‡ä»¶è€Œä¸æ˜¯ç¼“å­˜é“¾æ¥ï¼Œæ–¹ä¾¿ç§»åŠ¨
            huggingface-cli download "$repo_id" "$file_path" \
                --revision "$branch" \
                --local-dir "$dir" \
                --local-dir-use-symlinks False \
                --quiet # å‡å°‘æ—¥å¿—åˆ·å±ï¼Œæƒ³çœ‹è¿›åº¦å¯ä»¥å»æ‰è¿™è¡Œ
            
            if [ $? -eq 0 ]; then
                printf " âœ… [HF-CLI OK] %s\n" "$file_path"
                return 0
            else
                printf " âš ï¸ [HF-CLI FAIL] å°è¯•å›é€€åˆ° wget2: %s\n" "$filename"
                # å¦‚æœ CLI å¤±è´¥ï¼ˆæ¯”å¦‚ç‰ˆæœ¬ä¸å…¼å®¹ï¼‰ï¼Œä»£ç ä¼šè‡ªåŠ¨å¾€ä¸‹èµ°ï¼Œç”¨ wget2 å…œåº•
            fi
        fi
    fi

    # 3. é HF é“¾æ¥ï¼Œæˆ– HF ä¸‹è½½å¤±è´¥ï¼Œå›é€€åˆ° wget2 / wget
    local wget2_args="--max-threads=8 --progress=none --no-clobber --content-disposition"
    
    # æ„å»º Auth Header
    local header_args=""
    if [[ -n $auth_token ]]; then
        header_args="--header=\"Authorization: Bearer $auth_token\""
    fi
    
    if command -v wget2 &> /dev/null; then
        # æ³¨æ„ï¼šåœ¨ bash -c ä¸­æ­£ç¡®ä¼ é€’å¸¦å¼•å·çš„ header æ¯”è¾ƒéº»çƒ¦ï¼Œè¿™é‡Œç”¨ eval æˆ–è€…ç›´æ¥ cd è¿è¡Œ
        ( cd "$dir" && eval wget2 $header_args $wget2_args "\"$url\"" )
    else
        wget -q -nc --content-disposition --header="Authorization: Bearer $auth_token" -P "$dir" "$url"
    fi

    [ $? -eq 0 ] && printf " âœ… [WGET OK] %s\n" "$filename" || printf " âŒ [FAIL] %s\n" "$filename"
}

if [[ ! -f /.noprovisioning ]]; then
    provisioning_start
fi